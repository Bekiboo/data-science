---
title: "Client Report - Project 4: Can you predict that?"
subtitle: "Course DS 250"
author: "Julien Connault"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
    
---

## Elevator pitch
_TODO_

```{python}
# | label: Houses dataset
# | code-summary: Read project data

# libraries
import pandas as pd
import altair as alt
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# scikit learn froms
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn.naive_bayes import GaussianNB

# from sklearn.ensemble import GradientBoostingClassifier
# from sklearn.ensemble import AdaBoostClassifier
# from sklearn.ensemble import BaggingClassifier
# from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
from sklearn.metrics import accuracy_score

# load data
dwellings_denver = pd.read_csv("dwellings_denver.csv")
dwellings_ml = pd.read_csv("dwellings_ml.csv")
dwellings_neighborhoods_ml = pd.read_csv("dwellings_neighborhoods_ml.csv")

alt.data_transformers.enable("json")
```

```{python}

h_subset = dwellings_ml.filter(
    [
        "livearea",
        "stories",
        "numbaths",
        "basement",
        "nocars",
        "numbdrm",
        "sprice",
        "status_I",
        "before1980",
    ]
).sample(500)
sns.pairplot(h_subset, hue="before1980")
```

```{python}
corr = h_subset.drop(columns="before1980").corr()

sns.heatmap(corr)
```


## QUESTION|TASK 1
__Create 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.__

_TODO_

```{python}
# | label: Q1
# | code-summary: blah


plt.figure(figsize=(10, 6))
sns.scatterplot(data=dwellings_ml, x="livearea", y="sprice", hue="before1980")
plt.xlabel("Living Area (sqft)")
plt.ylabel("Sale Price ($)")
plt.title("Sale Price vs. Living Area")
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(data=dwellings_ml, x="livearea", y="basement", hue="before1980")
plt.xlabel("Living Area (sqft)")
plt.ylabel("Sale Price ($)")
plt.title("Sale Price vs. Living Area")
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=dwellings_ml, x="before1980", y="numbaths")
plt.xlabel("Before 1980 (0 = No, 1 = Yes)")
plt.ylabel("Number of Bathrooms")
plt.title("Boxplot of Number of Bathrooms vs. Before1980")
plt.show()

```


## QUESTION|TASK 2
__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.__

_TODO_

```{python}
# | label: Q2
# | code-summary:

# Step 0
X = dwellings_ml[
    [
        "basement",
        "nocars",
        "numbdrm",
        "sprice",
        "status_I",
        "livearea",
        "stories",
        "numbaths",
    ]
]
y = dwellings_ml["before1980"]

# %%
# Step 1
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=24, stratify=y
)
# %%
# Step 2
rf = RandomForestClassifier(random_state=24)  # Creating random forest object
rf.fit(X_train, y_train)  # Fit with the training data

# %%
# Step 3
y_pred = rf.predict(X_test)  # Using the features in the test set to make predictions

# %%
# Step 4
accuracy_score(y_test, y_pred)  # Comparing predictions to actual values
```

_TODO_

## QUESTION|TASK 3
__Justify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features.__

_TODO_

```{python}
# | label: Q3
# | code-summary:
feat_imports = pd.DataFrame(
    {"feature names": X_train.columns, "importances": rf.feature_importances_}
).sort_values("importances", ascending=False)

print(feat_imports.to_markdown(index=False))
```

## QUESTION|TASK 4
__Describe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.__

_TODO_

```{python}
# | label: Q4
# | code-summary:

```



## APPENDIX A (All Python Code)

```python
```
```
import pandas as pd
import altair as alt
import numpy as np

```
```
```
